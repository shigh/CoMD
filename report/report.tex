\documentclass[12pt]{article}
\usepackage[margin=1.0in]{geometry}

%\usepackage[utf8]{inputenc}
%\usepackage[T1]{fontenc}
%\usepackage{fixltx2e}
%\usepackage{longtable}
%\usepackage{float}
%\usepackage{wrapfig}
%\usepackage{rotating}
%\usepackage[normalem]{ulem}
%\usepackage{textcomp}
%\usepackage{marvosym}
%\usepackage{wasysym}
%\tolerance=1000

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{algpseudocode}
\usepackage{hyperref}

\usepackage{listings}

\lstset{language=C}
\newcommand{\pd}[2]{\frac{\partial #1}{ \partial #2}}
\renewcommand{\v}[1]{\bold{#1}}

\title{CS 598 Final Project}
\author{Scott High and Erin Molloy}
\date{\today}


\begin{document}

\maketitle

\section{Introduction}
Molecular dynamics (MD) simulations are important for researching physical phenomena 
such as, the electronic structure of metal and the folding trajectories of proteins. 
In our final project, we will create performance expectations for a molecular dynamics 
simulation mini-app, called \href{https://github.com/exmatex/CoMD}{\texttt{CoMD}}, which is designed to expose the core features 
of molecular dynamics simulations in a code base that is simple to understand and modify.

% Outline contributions

%In our final project, we will create performance expectations for the Lennart-Jones(LJ) model 
%of potential energy. We propose to
%\begin{itemize}
%    \item [1] Create a performance expectation based on memory access patterns.
%    \item [2] Create a performance expectation of scalability based on communication.
%    \item [3] Attempt to improve performance and scalability.
%    \item [4] Compare the scalability of the Lennart-Jones model to that of the Embedded Atom Model.
%\end{itemize}

\subsection{Background}
Molecular dynamics simulations model the movement of individual particles over time. 
Particle motion is determined by Newton's well-known equation of motion, $F = ma$. 
In an $N$-particle simulation, the force on the particle at position 
$\bm{r}_i = (x_i, y_i, z_i)$ is given by
\begin{equation*}
    F_i = m_i \ddot{\bm{r}}_i = -\frac{\partial}{\partial \bm{r}_i} U(\bm{r}_1, \dots, \bm{r}_N)
\end{equation*}
The system of first order ODEs is integrated to find the position of particles at each time step.
Both the LJ and EAM models utilize inter-particle interactions or ``pair potentials''
within a predefined region of interaction.


% Compilation requires only a valid \texttt{C} compiler and a working \texttt{MPI} implementation.
% The code is relatively short, only a few thousand lines, and is extensively documented. 

\section{Performance model}
All analysis is done assuming a one-level cache model and
approximating read and write times as equal.  The constants used in
the performance expectations are determined by the clock rate and
\texttt{STREAM} benchmark results as measured on Blue Waters.

The equations we are calculating for each particle in computer variables are
\begin{align}
  E_{tot} &= \sum_{ij} U_{LJ}(r_{ij}) \\
  U_{LJ}(r_{ij}) &= 
  A\left(\frac{1}{r_{ij}}\right)^{6}\left\{ \left(\frac{1}{r_{ij}}\right)^{6} - 1 \right\} \\
  \notag\\
  \textbf{F}(r_{ij}) &= - U'_{LJ}(r_{ij})\hat{r}_{ij} \notag\\
      &=  24 \frac{\epsilon}{r_{ij}} \left\{ 2 \left(\frac{\sigma}{r_{ij}}\right)^{12}
              - \left(\frac{\sigma}{r_{ij}}\right)^6 \right\} \hat{r}_{ij} \notag\\
              &=  A \frac{1}{r_{ij}^2} \left(\frac{1}{r_{ij}}\right)^{6} \left\{ 2 \left(\frac{1}{r_{ij}}\right)^{6}
              - 1 \right\} \textbf{r}_{ij}
\end{align}
in a fully periodic domain. The total number of simulation particles
is $N$, and each particle has $n$ neighbors within
$r_c=r_{\text{cutoff}}$.

We develope our performance model by calculating the cost of updating
particle $i$ and its interaction with each of its $n$ neighbors
$j$. The cost is:
\begin{itemize}
\item[A)] 3 loads for particle $i$'s position
\item[B)] For each particle $j$ where $r_{ij}<r_c$
  \begin{enumerate}
    \item $3$ loads for particle $j$'s position
    \item 3 subtractions, 3 multiplications, 2 additions and 1 division to calculate $\frac{1}{r_{ij}^2}$ 
    \item 3 multiplications to calculate $\left(\frac{1}{r_{ij}^2}\right)^3=\left(\frac{1}{r_{ij}}\right)^6$
    \item 2 subtractions and 2 multiplications to calculate $U_{LJ}$ (1 subtraction is for cutoff potential)
    \item 3 multiplications and 1 subtraction to calclulate $F(r_{ij})$
    \item 3 multiplications and 3 additions to calculate and update $F_{x,y,z}$
  \end{enumerate}
\item[C)] 1 write to save $U_{LJ}$. (Assume we can save the $U_{LJ}(r_{ji})$ term for free)
\item[D)] 3 writes to save $F_{x,y,z}$
\item[E)] 1 addition to update $E$
\end{itemize}
The total cost is $N(A+nB/2)+C+D+E$, where the $1/2$ is to account for
double counting. Using $c$ for the cost of a floating point operation,
$w$ for the cost of a write and $r$ for the cost of a read the
estimated cost is
\begin{equation}
N \left(\frac{n}{2} \left(26 c + 3 w\right) + 3 w\right) + c + 4 r
\end{equation}
Approximating reads and writes as equal reduces this to
\begin{equation}
  N \left(\frac{n}{2} \left(26 c + 3 r\right) + 3 r\right) + c + 4 r
  \label{eqn:perf-model}
\end{equation}
We approximate $n$ by noting that the density of atoms in an FCC
lattice is 4 atoms/cell, so the average number of particles within in
a sphere of radius $r_c$ is $n \approx 4\frac{4\pi}{3}r_c^3\approx69$.
We approximate $c=4.35\times10^{-10}\;\text{flops}/s$ using the clock
rate and $r=1.43\times10^{-9}\;\text{B}/s$ using the STREAM benchmark
on Bluewaters. The results of this performance model are shown as
model 1 in figure \ref{fig:perf-models}.

The data structure used for storing the computational particles is a
struct of linear C arrays. Each linear array is divided into equal
sized sections which store information for particles in a region of
the simulation domain. The size of the sections is the maximum number
of particles per region of space, and does not change throughout the
simulation. This ordering of particles is used to efficently determine
which particle pairs are within the cutoff radius.

This performance model represents a best case scenario for the number
of operations required to compute the inter-particle forces. To better
test the implementation we also developed performance models that
match the algorithm used. This requires adding a term to take into
account the work required to check if a particle is within
$r_c$. Denote the number of particles checked that are not within
$r_c$ as $k$. Each check requires 3 reads, 3 subtractions, 3
multiplications and 2 additions to calculation $\| x_i-x_j\|_2^2$,
giving us the performanced model
\begin{equation}
  N \left(\frac{n}{2} \left(26 c + 3 r\right)+\frac{k}{2} \left(8 c + 3 r\right) + 3 r\right) + c + 4 r
  \label{eqn:perf-model-nk}
\end{equation}
The actual implementation does not compute interactions and distance
checks only once, but rather does so for each particle. This doubles
the number of interactions and distance checks over the performance
model \ref{eqn:perf-model-nk} to give
\begin{equation}
  N \left(n \left(26 c + 3 r\right)+k \left(8 c + 3 r\right) + 3 r\right) + c + 4 r
  \label{eqn:perf-model-2n2k}
\end{equation}

% include picture of particle lattice...

% Graphs -- Erin

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{../figs/perfmodel_forceLJ}
  \caption{Performance models and baseline results. Model 1 is
    equation \ref{eqn:perf-model} with $n=69$ and model 2 is
    \ref{eqn:perf-model} with $n=2\times69$.}
  \label{fig:perf-models}
\end{figure}

\section{Performance Baseline}
% Erin Molloy

A baseline for the force routine was established by running the code
on a single processor with *settings* using the default Cray
compiler. This was then compared with the performance models
\ref{eqn:perf-model}-\ref{eqn:perf-model-2n2k} developed above. The
results are shown in figure \ref{fig:perf-models}. Clearly, the
baseline using the Cray compiler does not agree well with the results
of our performance models. We were unable to determine why the Cray
compiler has such low performance, and ran additional baselines using
code compiled with gcc 4.7.1. The baseline run with gcc gave excellent
agreement with our performance model \ref{eqn:perf-model-2n2k} which
was developed to describe the algorithim actually used.

\subsection{Strong scaling}

\subsection{Weak scaling}

\section{Modifications}
\label{sec:mods}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{../figs/modified_forceLJ}
  \caption{Runtime and speedups from the modifications described in
    section \ref{sec:mods}}
  \label{fig:mod-force}
\end{figure}

The performance baseline revelead a large discrepancy between our
performance model and experimental results for the Cray compiler. We
have focused our modifications on attempting to improve the results
using the Cray compiler. The results using the gcc compiler agree well
with our performance model, and further improvements would require
changes to the underlying data structures or a complete rewrite of the
force calculation routines, both of which are beyond the scope of this
project.

The first thing we noticed while analyzing the source code is a large
number of pointer dereferences to access the arrays storing particle
information. From the code report generated by the Cray compiler it
was clear that these dereferences were being done everytime the
pointers were accessed in the innermost loop of the force
calcuation. A simple optimzation was then to derefernce these pointers
before the computation. The small loops over real3 variables are also
not unrolled by compiler, so we did this by hand. The inner loop of
the force calculation routine is shown before and after optimization
in appendix \ref{apd:code-changes}.

The Cray compiler reports tell us that no vectorization is occuring in
the force calculation. After investgating we determined that this is
in fact the correct behavior, as the data structure used does not
guarantee that the arrays used are not aliased. All particle
information is stored in contigous arrays and aliasing occurs when
calculating the interactions between particles in the same cell. We
considered modifiying the data structure to remove aliasing, but
determined that the modifications required are beyond the scope of
this project.

Another potential improvement considered was changing the order of
particles within a cell to improve memory access patterns. The code
currently sorts the particles within a cell regularly. Because of this
it is unlikely that substational improvements could be made.

After the above modification were made the runtimes using the Cray
compiler were still several orders of magnitude higher than our
performance expectations. With no clear reason for this discrepency we
ran our single core bencharks using code compiled with gcc and found
that the runtime decreased dramatically. From the gcc compiler report
it was clear that no additional vectorization was occuring. We have
been unable to determine the reason for the large difference between
compilers.

\section{Conclusion}
% REFERENCES???



\appendix
\section{Code changes}
\label{apd:code-changes}
The changes made to the inner loop in the force cacluation are shown
here.
\subsection{Initial Inner Force Loop}
\begin{lstlisting}
  real_t dr[3];
  int jId = s->atoms->gid[jOff];  
  if (jBox < s->boxes->nLocalBoxes && jId <= iId )
  continue; // don't double count local-local pairs.
  real_t r2 = 0.0;
  for (int m=0; m<3; m++)
  {
    dr[m] = s->atoms->r[iOff][m]-s->atoms->r[jOff][m];
    r2+=dr[m]*dr[m];
  }

  if ( r2 > rCut2) continue;

  r2 = 1.0/r2;
  real_t r6 = s6 * (r2*r2*r2);
  real_t eLocal = r6 * (r6 - 1.0) - eShift;
  s->atoms->U[iOff] += 0.5*eLocal;
  s->atoms->U[jOff] += 0.5*eLocal;

  if (jBox < s->boxes->nLocalBoxes)
  ePot += eLocal;
  else
  ePot += 0.5 * eLocal;

  real_t fr = - 4.0*epsilon*r6*r2*(12.0*r6 - 6.0);
  for (int m=0; m<3; m++)
  {
    s->atoms->f[iOff][m] -= dr[m]*fr;
    s->atoms->f[jOff][m] += dr[m]*fr;
  }
\end{lstlisting}

\subsection{Optimized Inner Force Loop}
\begin{lstlisting}
  real_t dr[3];
  int jId = gid[jOff];  
  if (jBox < nLocalBoxes && jId <= iId )
  continue; // don't double count local-local pairs.

  real_t r2 = 0.0;
  dr[0] = r_iOff[0]-r[jOff][0];
  r2+=dr[0]*dr[0];
  dr[1] = r_iOff[1]-r[jOff][1];
  r2+=dr[1]*dr[1];
  dr[2] = r_iOff[2]-r[jOff][2];
  r2+=dr[2]*dr[2];

  if ( r2 > rCut2) continue;

  r2 = 1.0/r2;
  real_t r6 = s6 * (r2*r2*r2);
  real_t eLocal = r6 * (r6 - 1.0) - eShift;
  U[iOff] += 0.5*eLocal;
  U[jOff] += 0.5*eLocal;

  if (jBox < nLocalBoxes)
  ePot += eLocal;
  else
  ePot += 0.5 * eLocal;

  real_t fr = - 4.0*epsilon*r6*r2*(12.0*r6 - 6.0);
  f_iOff[0] -= dr[0]*fr;
  f[jOff][0] += dr[0]*fr;
  f_iOff[1] -= dr[1]*fr;
  f[jOff][1] += dr[1]*fr;
  f_iOff[2] -= dr[2]*fr;
  f[jOff][2] += dr[2]*fr;
\end{lstlisting}

\end{document}
